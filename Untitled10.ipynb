{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOHXLJMED8FMaQRb2IA9MY5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunmishrarut/RAG/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X3gOzhENrwa",
        "outputId": "24329844-7cb3-49f4-ddd6-8ff633f5b73b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf==5.6.0 in /usr/local/lib/python3.11/dist-packages (5.6.0)\n",
            "Requirement already satisfied: PyMuPDF==1.26.1 in /usr/local/lib/python3.11/dist-packages (1.26.1)\n",
            "Requirement already satisfied: langchain-community==0.3.25 in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (0.3.66)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (2.10.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (0.3.45)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.25) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.25) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.25) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community==0.3.25) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community==0.3.25) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community==0.3.25) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community==0.3.25) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community==0.3.25) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.25) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.25) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.25) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.25) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.25) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.25) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.25) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-community==0.3.25) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community==0.3.25) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community==0.3.25) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.25) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (1.3.1)\n",
            "Requirement already satisfied: rank_bm25==0.2.2 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25==0.2.2) (2.0.2)\n",
            "Requirement already satisfied: faiss-cpu==1.11.0 in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu==1.11.0) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu==1.11.0) (24.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
            "--2025-07-01 23:07:51--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206372 (202K) [application/octet-stream]\n",
            "Saving to: ‘data/Understanding_Climate_Change.pdf’\n",
            "\n",
            "data/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-07-01 23:07:51 (8.91 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n",
            "\n",
            "Context 1:\n",
            "researchers, and Deaf educators, facilitating data engineering for sign-language datasets for the MVP.\n",
            "Vedanta Resources PLC(Engineer - Data Scientist) May 2018 – Jul 2022\n",
            "• Automated reagents dosing in froth flotation circuits usingRandom Forestregression models andstatistical modeling\n",
            "in Python, increasing lead and zinc recovery by2.1% and 2.5% respectively, driving $5.9M additional annual\n",
            "revenue.\n",
            "• Processed 1.5 million rows from 106 data sources usingSQLand implemented optimizations that reduced power consump-\n",
            "tion by2%, saving $70,000 annually.\n",
            "• Applied Kanban agile practices in collaboration with global teams across various time zones, ensuring timely and\n",
            "effective project delivery.\n",
            "• Defined and measured performance metricsfor Heavy Earth Moving Machines (HEMM) and Ball Mills andreduced\n",
            "contract costfor underutilized HEMM equipment,saving $144,000 annually.\n",
            "Tata Steel Limited(Intern - Data Analyst) Apr 2016 Jul 2016\n",
            "\n",
            "\n",
            "Context 2:\n",
            "contract costfor underutilized HEMM equipment,saving $144,000 annually.\n",
            "Tata Steel Limited(Intern - Data Analyst) Apr 2016 Jul 2016\n",
            "• Analyzed water consumption data across 2,040 shifts and performed detailed water balance calculations across\n",
            "three plant sections using hydrological models, developing an interactivePower BI dashboardto identify inefficiencies,\n",
            "optimize usageto ensuregovernment environmental regulations compliance.\n",
            "Vedanta Resources PLC(Intern - Data Analyst) Apr 2015 Jul 2015\n",
            "• Developed robustETL pipelines and Power BI dashboards to visualize daily, monthly, and yearly production\n",
            "data, enabling operations and leadership teams to monitor performance trends and make data-driven decisions.\n",
            "Selected Projects\n",
            "Domain-Specific Medical LLM Fine-Tuning & Scalable QA Pipeline\n",
            "• Fine-tunedLlama2onmedicaldatasetsusingLow-RankAdaptation(LoRA),achievingupto 10xreductionsintraining\n",
            "time and GPU memory usageleveraging Hugging Face Transformers.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Install all required packages (run this cell first)\n",
        "!pip install pypdf==5.6.0\n",
        "!pip install PyMuPDF==1.26.1\n",
        "!pip install langchain-community==0.3.25\n",
        "!pip install rank_bm25==0.2.2\n",
        "!pip install faiss-cpu==1.11.0\n",
        "!pip install sentence-transformers\n",
        "\n",
        "# 2. Import all libraries\n",
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# 3. Download a sample PDF (climate change document)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
        "\n",
        "# 4. Helper function: Replace tabs with spaces in text chunks\n",
        "def replace_t_with_space(list_of_documents):\n",
        "    for doc in list_of_documents:\n",
        "        doc.page_content = doc.page_content.replace('\\t', ' ')\n",
        "    return list_of_documents\n",
        "\n",
        "# 5. Encode the PDF into a vector store using Hugging Face embeddings\n",
        "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
        "    # Load PDF and extract text\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
        "    )\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    cleaned_texts = replace_t_with_space(texts)\n",
        "\n",
        "    # Use Hugging Face embeddings (free)\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# 6. Set path to the document\n",
        "path = \"/content/ArunMishra_resume.pdf\"\n",
        "\n",
        "# 7. Encode the document (this may take a minute the first time)\n",
        "chunks_vector_store = encode_pdf(path, chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "# 8. Create a retriever to search for relevant chunks\n",
        "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "# 9. Function to retrieve and display context for a question\n",
        "def retrieve_context_per_question(question, chunks_query_retriever):\n",
        "    docs = chunks_query_retriever.get_relevant_documents(question)\n",
        "    context = [doc.page_content for doc in docs]\n",
        "    return context\n",
        "\n",
        "def show_context(context):\n",
        "    for i, c in enumerate(context):\n",
        "        print(f\"Context {i + 1}:\\n{c}\\n\\n\")\n",
        "\n",
        "# 10. Test the retriever with a sample question\n",
        "test_query = \"What is the main cause of climate change?\"\n",
        "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
        "show_context(context)\n",
        "\n",
        "# 11. (Optional) Try your own question!\n",
        "# your_query = \"Type your question here\"\n",
        "# context = retrieve_context_per_question(your_query, chunks_query_retriever)\n",
        "# show_context(context)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Test the retriever with a sample question\n",
        "test_query = \"What is the main cause of climate change?\"\n",
        "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
        "show_context(context)\n",
        "\n",
        "# 11. (Optional) Try your own question!\n",
        "your_query = \"what is his qualification\"\n",
        "context = retrieve_context_per_question(your_query, chunks_query_retriever)\n",
        "show_context(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB0c5GhrNvAW",
        "outputId": "7fba29a5-760d-43b2-da07-0b1a02624808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context 1:\n",
            "researchers, and Deaf educators, facilitating data engineering for sign-language datasets for the MVP.\n",
            "Vedanta Resources PLC(Engineer - Data Scientist) May 2018 – Jul 2022\n",
            "• Automated reagents dosing in froth flotation circuits usingRandom Forestregression models andstatistical modeling\n",
            "in Python, increasing lead and zinc recovery by2.1% and 2.5% respectively, driving $5.9M additional annual\n",
            "revenue.\n",
            "• Processed 1.5 million rows from 106 data sources usingSQLand implemented optimizations that reduced power consump-\n",
            "tion by2%, saving $70,000 annually.\n",
            "• Applied Kanban agile practices in collaboration with global teams across various time zones, ensuring timely and\n",
            "effective project delivery.\n",
            "• Defined and measured performance metricsfor Heavy Earth Moving Machines (HEMM) and Ball Mills andreduced\n",
            "contract costfor underutilized HEMM equipment,saving $144,000 annually.\n",
            "Tata Steel Limited(Intern - Data Analyst) Apr 2016 Jul 2016\n",
            "\n",
            "\n",
            "Context 2:\n",
            "contract costfor underutilized HEMM equipment,saving $144,000 annually.\n",
            "Tata Steel Limited(Intern - Data Analyst) Apr 2016 Jul 2016\n",
            "• Analyzed water consumption data across 2,040 shifts and performed detailed water balance calculations across\n",
            "three plant sections using hydrological models, developing an interactivePower BI dashboardto identify inefficiencies,\n",
            "optimize usageto ensuregovernment environmental regulations compliance.\n",
            "Vedanta Resources PLC(Intern - Data Analyst) Apr 2015 Jul 2015\n",
            "• Developed robustETL pipelines and Power BI dashboards to visualize daily, monthly, and yearly production\n",
            "data, enabling operations and leadership teams to monitor performance trends and make data-driven decisions.\n",
            "Selected Projects\n",
            "Domain-Specific Medical LLM Fine-Tuning & Scalable QA Pipeline\n",
            "• Fine-tunedLlama2onmedicaldatasetsusingLow-RankAdaptation(LoRA),achievingupto 10xreductionsintraining\n",
            "time and GPU memory usageleveraging Hugging Face Transformers.\n",
            "\n",
            "\n",
            "Context 1:\n",
            "public speaking and job readiness through mock group discussions, interview simulations and other events.\n",
            "• Completed 500+ hours of active practicein presentations, public speaking, and body language.\n",
            "• Ranked in the top 0.8% out of 1 million candidatesin the IIT-Joint Entrance Examination 2013, India.\n",
            "• Achieved 98.7 percentile among 300,000+ candidatesin the Common Admission Test (CAT) 2022, India.\n",
            "\n",
            "\n",
            "Context 2:\n",
            "high-performing models across crisis periods.\n",
            "Skills\n",
            "Technical Skills: Python, R, SQL, Pandas, NumPy,Machine Learning Ensemble Models, Deep Learning,\n",
            "ETL, Scikit-Learn,TensorFlow, PyTorch, Keras,Transformers, Hugging Face, Power BI, Tableau, Matplotlib,\n",
            "Seaborn, MySQL, PostgreSQL, MongoDB,hypothesis testing, A/B testing, Bayesian methods, time series\n",
            "analysis, advanced analytics, MS Office (Word, Excel, PowerPoint)\n",
            "Soft Skills: Leadership & Team Coordination, Interpersonal Communication, Facilitation, Presentation\n",
            "Skills, Analytical Thinking, Adaptability,Business Acumen\n",
            "Leadership Activities and Honors\n",
            "• Elected Placement Representative and Coordinator for theStudent Body at IIT Dhanbad.\n",
            "• Founded \"Vakta [Orator]\", a Toastmasters International-inspired club, empowering 100+ students to enhance\n",
            "public speaking and job readiness through mock group discussions, interview simulations and other events.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "it5OzXY6P5g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydf==5.6.0 # Pure python pdf library that is it is compeltely written in python only\n",
        "!pip install PyMuPDF=1.26.1 #high performance PDF library but has C dependencies\n",
        "!pip install langchain_community==0.3.25 #library to access community mainted third-part integration of langchain ecosystem\n",
        "!pip install rank_bm25=0.2.2 # employees BM25 algorithm which in turn used for ranking documents based on their relevence to the querry. MOre occurences means more releted to the querry.\n",
        "!pip install faiss-cpu=1.11.0 #library made by facebook to seach a relevant vectors ( to the querry) even in a large dataset.\n",
        "! pip install sentence-tranformers #library to provide models to create vector embeddings."
      ],
      "metadata": {
        "id": "Dfvp6pmXsBCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from lanchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splotter import RecursiveCHaracterTextSplitter\n",
        "from lanhchain-community.embeddings import HuggingFaceEmbeddings #uses distilbert as a deafault to generate embeddings. Can be changed as well\n",
        "from langchain.vectorstoes import FAISS"
      ],
      "metadata": {
        "id": "5FLTkwDiv1fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path =\"File_Name.pdf\""
      ],
      "metadata": {
        "id": "TDl8JlG1v1pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(path)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "6zEBo5JSv1u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 1000\n",
        "chunk_overlap = 200\n"
      ],
      "metadata": {
        "id": "kkSKKKI4v1za"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}